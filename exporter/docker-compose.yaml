version: "3.7"
services:
  # nvidia-smi-exporter
  nvidia-smi-exporter:
    container_name: nvidia-smi-exporter
    image: utkuozdemir/nvidia_gpu_exporter:1.1.0
    ports:
      - 9835:9835
    devices:
      - /dev/nvidiactl:/dev/nvidiactl
      - /dev/nvidia0:/dev/nvidia0
    volumes:
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
      - /usr/bin/nvidia-smi:/usr/bin/nvidia-smi
    restart: unless-stopped
  # dcgm-exporter
  dcgm-exporter:
    container_name: dcgm-exporter
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.3.7-3.5.0-ubuntu22.04
    restart: always
    volumes:
      - ./dcp-metrics-included.csv:/etc/dcgm-exporter/default-counters.csv
    ports:
      - 9400:9400
    cap_add:
      - SYS_ADMIN
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  # node-exporter
  node-exporter:
    container_name: node-exporter
    image: prom/node-exporter:latest
    restart: always
    network_mode: "host"
    pid: "host"
    volumes:
      - /:/host:ro,rslave
    command:
      - "--path.rootfs=/root"
  # mfu-exporter
  mfu-exporter:
    container_name: mfu-exporter
    image: mfu-exporter:v1.0.0
    restart: always
    environment:
      - AI_METRICS_LABEL=mfu
      - NODE_LABEL="your node unique flag" # 修改处
      - LOKI_URL="your loki url" # 修改处
    ports:
      - 9133:9133